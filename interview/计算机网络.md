## 七层

应用层，表示层，会话层，传输层，网络层，数据链路层，物理层

TCP/IP
分为四层：应用层、传输层、网络层、链路层
##ipv4和ipv6的区别ipv6:128位地址空间，内置网络层安全，无状态地址自动配置
当你输入域名访问一个网站的时候，背后的过程是什么？
1.域名解析：DNS解析IP2.建立TCP连接：3.获取网页内容：
无状态协议
把每个请求作为与之前任何请求都无关的独立的事务的服务器每次请求都是独立的，没有上下文的关系
幂等性
请求一次和请求N次具有相同的副作用get,delete，put(具有幂等性)post(不具有幂等性)
HTTP的请求消息：请求行，请求头部，空行，请求数据
请求行：请求方法字段，URL，HTTP协议
HTTP的响应消息：
状态行，响应头，空行，响应正文
HTTP报文头部有哪些字段
请求头（Request)1.Accept:告诉服务器客户端浏览器这边可以处理什么数据2.Accept_Encodeing :gzip告诉服务器我支持什么样的压缩格式3.Accept_language：告诉服务器支持的语言4.cache_control:告诉服务器是否缓存5.connection:模式为keepalive6.Host:远程服务器的域名7.referer:当前页面上的一个页面地址
返回头（response)1.cache_control:要不要缓存2.connection；keep_live服务器同意保持连接3.content_length；内容的长度4.content_type:返回内容支持的格式5.Data:时间6.server：ngnix服务器类型
#HTTP的状态码：1.指示信息_表示请求已经接收，继续处理(已经接收到一部分)2.成功——表示请求已经被成功接收，理解3.重定向——表示完成请求必须金聪更进一步的操作4.客户端错误5.服务器端错误
DNS解析
1.在浏览器中输入www . qq .com 域名，操作系统会先检查自己本地的hosts文件是否有这个网址映射关系，如果有，就先调用这个IP地址映射，完成域名解析。2.如果hosts里没有这个域名的映射，则查找本地DNS解析器缓存，是否有这个网址映射关系，如果有，直接返回，完成域名解析。3.如果hosts与本地DNS解析器缓存都没有相应的网址映射关系，首先会找TCP/ip参数中设置的首选DNS服务器，在此我们叫它本地DNS服务器，此服务器收到查询时，如果要查询的域名，包含在本地配置区域资源中，则返回解析结果给客户机，完成域名解析，此解析具有权威性。4.如果要查询的域名，不由本地DNS服务器区域解析，但该服务器已缓存了此网址映射关系，则调用这个IP地址映射，完成域名解析，此解析不具有权威性。5.如果本地DNS服务器本地区域文件与缓存解析都失效，则根据本地DNS服务器的设置（是否设置转发器）进行查询，如果未用转发模式，本地DNS就把请求发至13台根DNS，根DNS服务器收到请求后会判断这个域名(.com)是谁来授权管理，并会返回一个负责该顶级域名服务器的一个IP。本地DNS服务器收到IP信息后，将会联系负责.com域的这台服务器。这台负责.com域的服务器收到请求后，如果自己无法解析，它就会找一个管理.com域的下一级DNS服务器地址(http://qq.com)给本地DNS服务器。当本地DNS服务器收到这个地址后，就会找http://qq.com域服务器，重复上面的动作，进行查询，直至找到www . qq .com主机。6.如果用的是转发模式，此DNS服务器就会把请求转发至上一级DNS服务器，由上一级服务器进行解析，上一级服务器如果不能解析，或找根DNS或把转请求转至上上级，以此循环。不管是本地DNS服务器用是是转发，还是根提示，最后都是把结果返回给本地DNS服务器，由此DNS服务器再返回给客户机。
DNS劫持
1.又称域名劫持，是指在劫持的网络范围内拦截域名解析的请求，分析请求的域名，对特定的网络不能访问或者访问的是假网址
内容劫持
对运营商的缓存池做修改，导致用户的访问出错#HTTP工作原理HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。请求步骤：1.客户端连接到web服务器，建立tcp连接2.发送HTTP请求3.服务器解析请求返回HTTP相应4.释放连接TCP，若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;5.客户端浏览器解析HTML内容
例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程：1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;5、释放 TCP连接;6、浏览器将该 html 文本并显示内容;
#HTTPS协议：加了一层ssl,1.浏览器将自己支持的一套加密规则发送给网站。2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。3.获得网站证书之后浏览器要做以下工作a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。4.网站接收浏览器发来的数据之后要做以下的操作：a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。b) 使用密码加密一段握手消息，发送给浏览器5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。
#TCP和UDP的区别：TCP是可靠的，面向连接的字节流协议，UDP是不可靠的，无连接的数据报协议TCP：HTTP,FTPUDP:DNS,NFS
TCP 报文段的几个名词
seq:序列号，用来标记数据段的顺序，ack:确认号，期待接收对方的下一个报文段的第一个数据字节的序号确认ACK：占一位，仅当ACK=1时，确认字段才有效，ACK=0时表示，确认号无效同步SYN:建立连接时用于同步序号，当SYN=1,ACK=0表示这是一个连接请求报文 ，若同意，SYN=1,ACK=1;终止FIN:用来释放一个连接，FIN=1,表示发送完毕#TCP的三次握手，四次挥手过程：三次握手：1.主机A向主机B发送TCP连接请求数据包，其中包含主机的初始序列号SYN=1，SEQ=X2.主机B接收到请求后，发送SYN=1,ACK=1,SEQ=Y3.主机A接收主机B的确认报文后，发送一个序列号ACK=1,SEQ=X+1,ack=y+1;为什么需要第三次握手?简而言之：第三次握手，主机A发送一次确认是为了防止：如果客户端迟迟没有收到服务器返回的确认报文，这时他会放弃连接，重新启动一条连接请求；但问题是：服务器不知客户端没收到，所以他会收到两个连接请求，白白浪费了一条连接开销。四次挥手：1.关闭客户端到服务器的连接：首先客户端A发送一个FIN，用来关闭客户端到服务器端的数据传送，然后等待服务器的确认，其中标志位FIN=1，seq=u;2.服务器收到这个FIN，他发回一个ACK，确认好ack=u+1;3.关闭服务器到客户端的连接，服务器发送FIN=1给客户端4.客户收到FIN后，发回一个ACK报文确认，并将确认序号SEQ设置为收到序号加1，主机A发送FIN后，进入终止等待状态， 服务器B收到主机A连接释放报文段后，就立即给主机A发送确认，然后服务器B就进入close-wait状态，此时TCP服务器进程就通知高层应用进程，因而从A到B的连接就释放了。此时是“半关闭”状态。即A不可以发送给B，但是B可以发送给A。 此时，若B没有数据报要发送给A了，其应用进程就通知TCP释放连接，然后发送给A连接释放报文段，并等待确认。A发送确认后，进入time-wait，注意，此时TCP连接还没有释放掉，然后经过时间等待计时器设置的2MSL后，A才进入到close状态。https://blog.csdn.net/guyuealian/article/details/52535294
为什么需要四次握手
因为当服务端收到客户端的SYN连接请求报文后，可以直接发送SYN+ACK报文。其中ACK报文是用来应答的，SYN报文是用来同步的。但是关闭连接时，当服务端收到FIN报文时，很可能并不会立即关闭SOCKET，所以只能先回复一个ACK报文，告诉客户端，"你发的FIN报文我收到了"。只有等到我服务端所有的报文都发送完了，我才能发送FIN报文，因此不能一起发送。故需要四次挥手https://juejin.im/post/5d9c284b518825095879e7a5
Time_wait产生的原因及作用
1.为实现TCP全双工连接的可靠性:确保被动关闭方收到ACK，连接正常关闭，且不因被动关闭方重传FIN影响下一个新连接，否则主动关闭的一方传输层会用RST包相应对方，这会被对方认为是错误发生，然而这只是正常关闭，
2.为使旧的数据包在网络因过期而消失:2MSL报文最大生存时间，确保旧的数据不会影响连接
TCP和UDP相比，如何保证可靠性
1.校验和2.序列号/确认应答3.超时重传4.最大消息长度5.滑动窗口6.拥塞控制
TCP流量控制和拥塞控制的区别
流量控制：是端到端的控制，例如A通过网络给B发数据，A发送的太快导致B没法接收(B缓冲窗口过小或者处理过慢)，这时候的控制就是流量控制，原理是通过滑动窗口的大小改变来实现。拥塞控制：是A与B之间的网络发生堵塞导致传输过慢或者丢包，来不及传输。防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不至于过载。拥塞控制是一个全局性的过程，涉及到所有的主机、路由器，以及与降低网络性能有关的所有因素。拥塞控制的算法：1.慢开始：一开始不要发送大量的数据，由小到大逐渐增加窗口的大小，按照指数，2.拥塞避免算法：每次窗口大小加1， 达到阈值就是没有及时接收到，直接窗口降到1，设置新的慢开始阈值为(没有及时接收到阈值的一半)3.快重传: 发送方连续接收到3个重复确认，就立即重传4.快恢复: 立即将ssthresh门限减半，从减半的门限阈值开始执行，提高效率
数据链路层的功能：
1. 封装成帧：数据链路层必须具备一系列相应的功能，主要有：如何将数据组合成数据块（在数据链路层中将这种数据块称为帧，帧是数据链路层的传送单位）
2. 如何控制帧在物理信道上的传输，包括如何处理传输差错，如何调节发送速率以使之与接收方相匹配；在两个网路实体之间提供数据链路通路的建立、维持和释放管理。
   #阻塞io和非阻塞IO，同步IO和异步IO1.阻塞IO：应用进程操作IO时，资源不可用时，IO请求一直阻塞，直到反馈结果（有数据或超时）2.非阻塞IO：资源不可用时，IO请求离开返回，返回数据标识资源不可用1.同步IO：指的是应用程序和内核的交互，应用进程触发I/O操作，等待执行或者轮询，直到I/O操作完成，2.异步IO：应用进程触发操作后，直接返回，交给内核去执行，内核完成后通知应用进程
   #什么是线程同步？ 线程同步的方式和机制：线程同步：即当有一个线程在对内存进行操作时，其他线程都不可以对这个内存地址进行操作，直到该线程完成操作， 其他线程才能对该内存地址进行操作，而其他线程又处于等待状态。1.临界区：在任意时刻只允许一个线程对共享资源进行访问，如果有多个线程试图访问公共资源，那么在有一个线程进入后，其他试图访问公共资源的线程将被挂起，并一直等到进入临界区的线程离开，临界区在被释放后，其他线程才可以抢占。2.互斥对象：互斥对象和临界区很像，采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以能保证公共资源不会同时被多个线程同时访问。当前拥有互斥对象的线程处理完任务后必须将线程交出，以便其他线程访问该资源。
   IP寻址的工作原理
   ● 本地的网络寻址首先看本地网络实现IP 寻址，也就是我们所说的同一网段通信过程，现在我们假设有2个主机，他们是属于同一个网段。主机A和主机B，首先主机A通过本机的hosts表或者wins系统或dns系统先将主机B的计算机名 转换为Ip地址，然后用自己的 Ip地址与子网掩码计算出自己所出的网段，比较目的主机B的ip地址与自己的子网掩码，发现与自己是出于相同的网段，于是在自己的ARP缓存中查找是否有主机B 的mac地址，如果能找到就直接做数据链路层封装并且通过网卡将封装好的以太网帧发送有物理线路上去：如果arp缓存中没有主机B的的mac地址，主机A将启动arp协议通过在本地网络上的arp广播来查询主机B的mac地址，获得主机B的mac地址厚写入arp缓存表，进行数据链路层的封装，发送数据。
   ● 非本地网络寻址其实，假设2个主机不是同的网段，此时他们的通信过程又是怎么样的呢？ 不同的数据链路层网络必须分配不同网段的Ip地址并且由路由器将其连接起来。主机A通过本机的hosts表或wins系统或dns系统先主机B的计算机名转换为IP地址，然后用自己的Ip地址与子网掩码计算出自己所处的网段，比较目的目的主机B的Ip地址，发现与自己处于不同的网段。于是主机A将知道应该将次数据包发送给自己的缺省网关，即路由器的本地接口。主机A在自己的ARP缓存中查找是否有缺省网关的MAC地址，如果能够找到就直接做数据链路层封装并通过网卡 将封装好的以太网数据帧发送到物理线路上去，如果arp缓存表中没有缺省网关的Mac地址，主机A将启动arp协议通过在本地网络上的arp广播来查询缺省网关的mac地址，获得缺省网关的mac地址后写入arp缓存表，进行数据链路层的封装，发送数据。数据帧到达路由器的接受接口后首先解封装，变成ip数据包，对ip 包进行处理，根据目的Ip地址查找路由表，决定转发接口后做适应转发接口数据链路层协议帧的封装，并且发送到下一跳路由器，次过程继续直至到达目的的网络与目的主机。
   ip和mac 区别
   [https://blog.csdn.net/ENSHADOWER/article/details/88221609?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-4.nonecase]
icmp协议 ，arp,rarp
   arp: 根据IP地址获取物理地址mac的协议rarp：反向地址转换协议允许局域网的物理地址mac从网关服务器的arp表或者缓存上请求其IP，icmp: 主要用于主机和路由器之间传递消息
   怎么解决TCP拆包分包问题
   TCP的内核工作原理说一说
   [https://www.cnblogs.com/clschao/articles/9585555.html]
在HTTP层如何保证数据有序？
   [http://www.ruanyifeng.com/blog/2017/06/tcp-protocol.html]
定时器的工作原理及实现
   对称加密和非对称的区别 非对称加密有哪些 AES的过程
   [http://www.ruanyifeng.com/blog/2014/09/illustration-ssl.html]对称加密又称私钥加密，加密和解密用的是同样的密钥(DES,3DES,AES,IDEA)非对称加密又称公钥加密，它使用公钥和私钥进行加密(SSH, HTTPS,TLS,电子证书) rsa
   银行家问题
   当一个进程申请资源的时候，银行家算法通过分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态
   HTTP1.0 ，1.2，2.0区别
   HTTP 1.0
   ● 无状态，无连接；
   ● 短连接：每次发送请求都要重新建立tcp请求，即三次握手，非常浪费性能；
   ● 无host头域，也就是http请求头里的host；
   ● 不允许断点续传，而且不能只传输对象的一部分，要求传输整个对象。
   HTTP 1.1
   ● 长连接，流水线，使用connection:keep-alive使用长连接；
   ● 请求管道化；
   ● 增加缓存处理(新的字段如cache-control)；
   ● 增加Host字段，支持断点传输等；
   ● 由于长连接会给服务器造成压力。
   HTTP 2.0
   ● 二进制分帧；
   ● 多路复用(或连接共享)，使用多个stream，每个stream又分帧传输，使得一个tcp连接能够处理多个http请求；
   ● 头部压缩，双方各自维护一个header的索引表，使得不需要直接发送值，通过发送key缩减头部大小；
   ● 服务器推送(Sever push)。
   HTTP 3.0
   ● 基于google的QUIC协议，而quic协议是使用udp实现的；
   ● 减少了tcp三次握手时间，以及tls握手时间；
   ● 解决了http 2.0中前一个stream丢包导致后一个stream被阻塞的问题；
   ● 优化了重传策略，重传包和原包的编号不同，降低后续重传计算的消耗；
   ● 连接迁移，不再用tcp四元组确定一个连接，而是用一个64位随机数来确定这个连接；
   ● 更合适的流量控制。



http2.多路复用
HTTp/1中每次请求都会建立一次HTTP连接 ，有两个问题需要解决1.多个文件传输需要一个一个进行2.连接数过多，需要等待有两个概念，帧和流（一个TCP连接中存在多个流，每个帧可以找到所属的流）
cookie和session的区别
cookie主要用于存放在浏览器，可以设置最大存活时间，session用于存放在服务器，用来存储特定用户会话所需的信息1.存放位置不同，2.存取方式不同3.安全性(策略)不同4.有效期不同1，session 在服务器端，cookie 在客户端（浏览器）2，session 默认被存在在服务器的一个文件里（不是内存）3，session 的运行依赖 session id，而 session id 是存在 cookie 中的，也就是说，如果浏览器禁用了 cookie ，同时 session 也会失效（但是可以通过其它方式实现，比如在 url 中传递 session_id）4，session 可以放在 文件、数据库、或内存中都可以。5，用户验证这种场合一般会用 session
内存拷贝函数memcpy、strcpy原理
进程和线程、上下文切换了什么、共享了什么

#HTTP工作原理
HTTP协议采用了请求/响应模型。客户端向服务器发送一个请求报文，请求报文包含请求的方法、URL、协议版本、请求头部和请求数据。服务器以一个状态行作为响应，响应的内容包括协议的版本、成功或者错误代码、服务器信息、响应头部和响应数据。
请求步骤：
1.客户端连接到web服务器，建立tcp连接
2.发送HTTP请求
3.服务器解析请求返回HTTP相应
4.释放连接TCP，若connection 模式为close，则服务器主动关闭TCP连接，客户端被动关闭连接，释放TCP连接;若connection 模式为keepalive，则该连接会保持一段时间，在该时间内可以继续接收请求;
5.客户端浏览器解析HTML内容
例如：在浏览器地址栏键入URL，按下回车之后会经历以下流程：
1、浏览器向 DNS 服务器请求解析该 URL 中的域名所对应的 IP 地址;
2、解析出 IP 地址后，根据该 IP 地址和默认端口 80，和服务器建立TCP连接;
3、浏览器发出读取文件(URL 中域名后面部分对应的文件)的HTTP 请求，该请求报文作为 TCP 三次握手的第三个报文的数据发送给服务器;
4、服务器对浏览器请求作出响应，并把对应的 html 文本发送给浏览器;
5、释放 TCP连接;
6、浏览器将该 html 文本并显示内容;
#HTTPS协议：
加了一层ssl,
1.浏览器将自己支持的一套加密规则发送给网站。
2.网站从中选出一组加密算法与HASH算法，并将自己的身份信息以证书的形式发回给浏览器。证书里面包含了网站地址，加密公钥，以及证书的颁发机构等信息。
3.获得网站证书之后浏览器要做以下工作
● a) 验证证书的合法性（颁发证书的机构是否合法，证书中包含的网站地址是否与正在访问的地址一致等），如果证书受信任，则浏览器栏里面会显示一个小锁头，否则会给出证书不受信的提示。
● b) 如果证书受信任，或者是用户接受了不受信的证书，浏览器会生成一串随机数的密码，并用证书中提供的公钥加密。
● c) 使用约定好的HASH计算握手消息，并使用生成的随机数对消息进行加密，最后将之前生成的所有信息发送给网站。
4.网站接收浏览器发来的数据之后要做以下的操作：
● a) 使用自己的私钥将信息解密取出密码，使用密码解密浏览器发来的握手消息，并验证HASH是否与浏览器发来的一致。
● b) 使用密码加密一段握手消息，发送给浏览器5.浏览器解密并计算握手消息的HASH，如果与服务端发来的HASH一致，此时握手过程结束，之后所有的通信数据将由之前浏览器生成的随机密码并利用对称加密算法进行加密。
网络
网络安全
网络攻击
●  XSS (Cross Site Scripting，跨站脚本攻击)：恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。XSS的原理是WEB应用程序混淆了用户提交的数据和JS脚本的代码边界，导致浏览器把用户的输入当成了JS代码来执行。
○ 预防策略：XSS攻击能够实现的主要原因是对用户的输入进行了原样的输出，因此把控输入输出环节即可。页面限制输入长度、特殊字符限制，后端代码限制输入长度、处理特殊字符，Filter过滤器统一处理。输出时对字符进行转义处理，各种模板都有相关语法，注意标签的正确使用。
● CSRF (Cross Site Request Forgery，跨站请求伪造攻击)：CSRF攻击能够盗用身份，以我们的名义发送恶意请求，发送邮件，发消息，盗取账号，购买商品，虚拟货币转账等。通过伪装成来自受信任用户的请求来利用受信任的网站。
○ 预防策略：① 验证HTTP Referer字段，它记录了该HTTP请求的来源地址，在通常情况下，访问一个安全受限页面的请求其referer需要来自同一个网站；② 添加token并验证，CSRF能够成功完全是因为黑客能够伪造用户的请求，在该请求中所有的用户验证信息都存在于cookie中，因此黑客才可以利用cookie来通过安全验证。要抵御CSRF，关键在于在请求中放入黑客不能伪造的信息，并且该信息不存在在cookie中。那么我们就可以在HTTP请求中以参数的形式加入一个随机生成的token，并在服务器端建立一个拦截器来验证这个token，如果请求中没有token或token的内容的不正确，则认为不安全从而直接拒绝该请求。
● SQL注入：在用户输入的字符串中加入 SQL 语句，如果在设计不良的程序中忽略了检查，那么这些注入进去的 SQL 语句就会被数据库服务器误认为是正常的 SQL 语句而运行，攻击者就可以执行计划外的命令或访问未被授权的数据。
○ 预防策略：① 过滤输入内容，校验字符串，过滤输入内容就是在数据提交到数据库之前，就把用户输入中的不合法字符剔除掉。② 参数化查询，目前被视作是预防 SQL 注入攻击最有效的方法。参数化查询是指在设计与数据库连接并访问数据时，在需要填入数值或数据的地方，使用参数（Parameter）来给值。③ 限制数据库权限和特权，限制攻击者在设法获取访问权限时可以执行的操作。④ 避免直接向用户显示数据库错误，攻击者可以使用这些错误消息来获取有关数据库的信息。
● DoS 攻击(拒绝服务攻击)：使系统过于忙碌而不能执行有用的业务并且占尽关键系统资源。它是基于这样的思想：用数据包淹没本地系统，以打扰或严重阻止捆绑本地的服务响应外来合法的请求，甚至使本地系统崩溃。https://www.cnblogs.com/ColoFly/p/16639868.html
○ SYN 泛洪：利用TCP建立连接时需要进行三次握手的过程，并结合IP源地址欺骗实现的。
○ Ping 泛洪：其原理是强制让系统消耗大多数时间进行无用的应答，降低系统网络质量。主要实现的方法有：①将ping包的源地址伪装成受害者的地址并向整个主机所在的网络广播echo请求，这样的请求消息能够造成很多的响应发送的受害者机器；②通过互联网在受害者机器安装木马程序并在某时刻向某主机发送大量echo请求；③攻击者发送更多简单的ping泛洪来淹没数据连接。
● 侧信道攻击：利用计算机不经意间释放出的信息信号，如：功耗，电磁辐射，电脑硬件运行声等来进行破译的攻击模式。
HTTP
接口幂等性了解吗？
幂等性是指，对于一个操作，不论执行多少次，产生的结果都是一样的，不会因为多次操作几次而产生了副作用。
● 对于查询操作而言，查询一次和查询多次，在数据不变的情况下，查询结果是一样的，因为在数据库中 Select 语句本身就是幂等操作。
● 对于删除操作而言，也是幂等的，删除一次和多次删除都是把数据删除。虽然可能因为数据本身的情况不一样导致返回的结果不一样，比如删除不存在着的数据和删除存在的数据，但是在相同情况下返回的结果是一致的，所以删除也具有幂等性。
● 对应新增操作而言，在重复提交的场景下会出现幂等性问题，这种情况需要使用一些机制或方法来保证接口的幂等性：
○ 增加唯一索引，每次调用新增接口都能够和唯一索引建立联系，这样就能够防止新增脏数据；
○ 使用token机制，防止页面重复提交，保证页面的数据只能被提交一次。就是：数据提交前要向服务申请token并存储到缓存中，提交后台需要校验token，同时删除旧的token并生成新的token。
● 对于更新操作而言，在大多场景下结果一样，但是如果是增量修改是需要保证幂等性的，这种情况其实和新增操作类似，都是可以通过一些机制来保证幂等性的。
对HTTP报文的格式了解吗？
HTTP报文可以分为两类：请求报文 和 响应报文
○ 请求报文：请求报文包含请求行、请求头和请求体这三个部分，请求行有当前请求的方法（比如：GET/POST），还有URL和当前的协议版本信息。
○ 响应报文：响应报文的格式和请求报文类似，但是响应行和请求行所包含的信息不同，响应行只包含当前的协议版本和返回状态码这些信息。
为什么说HTTP是无状态的？
● 协议的状态是指下一次传输可以“记住”这次传输信息的能力。
● http是不会为了下一次连接而维护这次连接所传输的信息,为了保证服务器内存。
● 比如客户获得一张网页之后关闭浏览器，然后再一次启动浏览器，再登陆该网站，但是服务器并不知道客户关闭了一次浏览器。
● 由于Web服务器要面对很多浏览器的并发访问，为了提高Web服务器对并发访问的处理能力，在设计HTTP协议时规定Web服务器发送HTTP应答报文和文档时，不保存发出请求的Web浏览器进程的任何状态信息。这有可能出现一个浏览器在短短几秒之内两次访问同一对象时，服务器进程不会因为已经给它发过应答报文而不接受第二期服务请求。由于Web服务器不保存发送请求的Web浏览器进程的任何信息，因此HTTP协议属于无状态协议（Stateless Protocol）。
在这种客户端与服务器进行动态交互的Web应用程序出现之后，HTTP无状态的特性严重阻碍了这些交互式应用程序的实现，毕竟交互是需要承前启后的，简单的购物车程序也要知道用户到底在之前选择了什么商品。于是，两种用于保持HTTP状态的技术就应运而生了，一个是Cookie，而另一个则是Session。
HTTP长连接和短连接的区别？
长连接： 客户端和服务端建立连接后不进行断开，之后客户端再次访问这个服务器上的内容时，继续使用这一条连接通道。
短连接： 客户端和服务端建立连接，发送完数据后立马断开连接。下次要取数据，需要再次建立连接。
Http长连接和TCP长连接的区别
Http长连接 和 TCP长连接的区别在于: TCP 的长连接需要自己去维护一套心跳策略，而Http只需要在请求头加入 keep-alive:true 即可实现长连接。
长连接和短连接的优缺点？
● 长连接可以省去较多的tcp建立/关闭的操作，减少浪费，节省时间，对于频繁请求资源的客户，较适用于长连接；client和server如果长时间不关闭的话，会存在一个问题，随着客户的越来越多，server早晚会有扛不住的一天，这时需要采取一些策略，如关闭一些长时间不读写操作的连接，这样可以避免一些恶意连接导致server端服务受损，如果条件再允许，就可以以客户端为颗粒度，限制每个客户端的最大连接数
● 短连接对于服务器来说较为简单，存在的连接都是有用的连接，不需要额外的控制，但如果客户端连接频繁，会在tcp的建立和关闭上浪费时间。
HTTP状态码有哪些？
100，接受的请求正在处理，信息类状态码
2xx(成功)表示成功处理了请求的状态码
● 200 OK
● 204 No Content
3xx(重定向)表示要完成请求，需要进一步操作。通常这些状态代码用来重定向
● 301，永久性重定向，表示资源已被分配了新的 URL
● 302，临时性重定向，表示资源临时被分配了新的 URL
● 303，表示资源存在另一个URL，用GET方法获取资源
● 304，(未修改)自从上次请求后，请求网页未修改过。服务器返回此响应时，不会返回网页内容
4xx(请求错误)这些状态码表示请求可能出错，妨碍了服务器的处理
● 400 Bad Request（请求不正确）
● 401表示发送的请求需要有通过HTTP认证的认证信息
● 403 Forbidden（禁止访问）
● 404 Not Found
5xx(服务器错误)这些状态码表示服务器在尝试处理请求时发生内部错误。这些错误可能是服务器本身的错误，而不是请求的错误
● 500，(服务器内部错误)服务器遇到错误，无法完成请求
● 502 Bad Gateway（网关错误）
● 503，表示服务器处于停机维护或超负载，无法处理请求
HTTP各个版本的区别是什么？
HTTP协议使用的版本有1.0、1.1、2.0、3.0，他们之前的区别是：
● HTTP/1.1 相比 HTTP/1.0 性能上的改进：
○ 长连接：HTTP/1.1 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。在一个TCP连接上可以传送多个HTTP请求和响应，减少了建立和关闭连接的消耗和延迟。
● HTTP/2.0 相比 HTTP/1.1 性能上的改进：
○ 多路复用：HTTP/2.0 可以在一个连接中并发多个请求和回应。
○ 头部压缩：HTTP/1.1 不支持请求头数据的压缩，HTTP2.0对请求头的数据进行压缩，合并同时发出请求的相同部分，这样数据体积小了，在网络上传输就会更快。
○ 服务器推送：HTTP/2.0的web server请求数据的时候，服务器会顺便把一些客户端需要的资源一起推送到客户端，免得客户端再次创建连接发送请求到服务器端获取。这种方式非常合适加载静态资源。服务不再是被动地响应，也可以主动向客户端发送消息。举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。
○ 二进制格式：HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制。
● HTTP/3.0：基于谷歌的QUIC，底层使用udp协议，https://baijiahao.baidu.com/s?id=1677802258258817086&wfr=spider&for=pc
HTTP 的请求头 (header) 常用的有哪些？
● Content-Type：代表当前的内容是什么格式的，比如json、html、xml、txt等。
● Content-Length：代表当前内容的长度，通常表示字节数量。
● Accept：指定所能接收的内容类型，和content-type类似。
● Cookie：cookie存放的是额外的信息，通常是由键值对来表示。
● Host：客户端请求的服务器的域名。
● Authorization：用于认证的信息。
HTTP协议中GET、POST、PUT、DELETE的区别？
GET、POST、PUT、DELETE这些是HTTP所定义的是与服务器交互的行为方法。通常来说，会使用GET来获取资源；会使用POST来向服务器提交数据；会使用DELETE来删除服务器上的资源；会使用PUT进行数据的修改。这几个对应的其实就是资源的增删改查操作，这是从它们的语义上进行区分的。
还有就是对于平常的业务而言，通过不同的行为方法来调用接口，其接口的幂等性通常会不同。《接口幂等性了解吗？》
REST接口是什么意思？
首先，我们使用的REST接口通常是指符合RESTful风格的接口，RESTful可以理解为一种接口使用规范。这些规范规定了怎么去使用HTTP协议来正确的调用接口，比如说在HTTP协议中的 POST、DELETE、PUT、GET 这4个动词用来表示对数据的增删改查操作；还规定了每个URL应该用来代表一种资源而不仅仅是一种路径。
优点：使用RESTful规范的好处就是 通过你调用的接口信息就知道这个接口的作用是什么，甚至不需要解释，就能够明白怎么去使用这个接口，一目了然，这是站在开发人员的角度去理解。
RPC接口了解吗？
RPC 指的是 远程过程调用，通俗地讲就是客户端能像调用本地函数一样去调用远程函数。因为RPC是远程调用其他主机上的服务，也就是说需要两台服务器，调用方在一台服务器上部署，另一台提供相关的服务，它们之间通过网络进行数据传输。
RPC通讯的大概过程：
首先，调用方调用RPC接口时，函数的参数经过序列化之后通过网络传输给服务提供方，然后服务提供方反序列化之后执行对应的函数，执行完成之后，同样将返回结果序列化并通过网络传回给调用方，调用方收之后经过反序列化获取到结果。
PRC关注的问题：
● 服务寻址：调用方需要知道自己调用的函数在哪台服务器上提供，一般的RPC框架通过服务注册，将自己提供的远程方法注册在服务注册中心上，然后调用方通过服务注册中心获取到服务提供方的IP地址等信息。
● 序列化和反序列化：调用方需要把函数的参数值传给远程的函数，双方需要约定如何解析传输内容，因此涉及到序列化和反序列化。通常情况下可以直接传输二进制数据、或者转化成JSON进行传输。
● 网络传输：远程调用往往用在网络上，客户端和服务端是通过网络连接的。所有数据都需要通过网络协议传输，大部分RPC框架使用TCP协议进行传输，也有直接使用HTTP协议进行传输的。
在浏览器输入URL之后发生了什么？

1. 浏览器做的第一步工作是解析 URL 中的信息（包括域名以及请求的文件资源信息）。
2. 生成相应的HTTP请求报文。
3. 浏览器需要根据URL中的域名查询真实的服务器IP地址，首先会通过系统hosts文件（linux系统的host在 /etc/hosts，windows系统的host在系统盘system目录）寻找相应的域名对应的IP地址，如果查询不到，则会通过DNS服务进行域名解析。
4. 通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈了。
5. HTTP 是基于 TCP 协议传输的，因此首先会经过传输层的 TCP 协议，然后经过网络层的IP协议，之后再经过数据链路层的以太网协议。
6. HTTP的请求报文会经过这些操作系统的协议栈，每经过一层都会在报文前面加上相应的首部信息。当然，通过TCP协议传输数据，首先需要经过三次握手建立连接。除此之外，在数据链路层可能还会涉及到其他协议，比如ARP协议。如果使用了HTTPS协议的话，还会涉及到SSL协议的加密和解密过程。
7. 最后报文会通过网卡和网线传输出去，然后经历交换机、路由器等网络设备的转发，直到报文到达服务器。
8. 服务器接收到报文之后，同样会通过系统的协议栈，一层一层向上递交数据，直到通过应用层解析请求的内容。
9. 然后服务器同理会将请求的内容按照这种方式返回给客户端。
10. 客户端的接收到请求的内容之后，会交给浏览器解析内容，并开始渲染浏览器的界面。
    HTTP 与 HTTPS 有哪些区别？
    ● HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题；HTTPS 使用了 SSL 安全协议，使得报文能够加密传输。
    ● HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL 的握手过程，才可进入加密报文传输。
    ● HTTP 的端口号是 80，HTTPS 的端口号是 443。
    ● HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。
    HTTPS 了解吗？
    HTTP的信息是明文传输，存在安全风险的问题，HTTPS使用了SSL安全协议进行加密传输，保证了数据的安全性。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL 协议，解决了信息被盗取、篡改等风险。
    ● HTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式保证了信息的机密性：
    ○ 在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。
    ○ 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。
    ● HTTPS 采用了摘要算法的方式来实现完整性，解决被篡改的风险。
    ● HTTPS 使用了数字证书，解决了被冒充的风险。
    SSL 的握手过程：
1. 客户端首先会通过服务端的数字证书获取到公钥；
2. 然后客户端会产生一个对称加密的会话秘钥，并使用服务端的公钥对该秘钥进行加密，然后发送给服务端；
3. 服务端接收到经过加密的数据之后，使用自己的非对称加密的秘钥进行解密获取到会话秘钥；
4. 自此之后，服务端和客户端之间就可以只用该会话秘钥进行加密通信了；
   TCP和UDP
   TCP 报文格式


TCP 3次握手的过程了解吗？

三次握手是TCP协议建立连接的过程，客户端和服务端之间需要发送3个数据包来建立TCP连接，1️⃣ 客户端首先会发送一个建立连接的请求包给服务端；2️⃣ 服务端接收到之后会返回一个建立连接的应答包；3️⃣ 客户端收到之后再次返回一个应答包给服务端；自此，TCP的连接就建立完成了。
为什么建立连接是三次握手？
● 首先，三次握手是为了保证双方都具有接受和发送能力。
● 更重要的是为了初始化数据包的序列号，通过序列号来保证数据的有序性。
○ 为了实现可靠数据传输，TCP 协议的通信双方，都必须维护一个序列号。三次握手的过程即是双方相互告知序列号起始值，并确认对方已经收到了序列号起始值的必经步骤。
○ 如果只是两次握手，至多只有连接发起方的起始序列号能被确认，另一方选择的序列号则得不到确认。
为什么TCP的初始序列号是随机的？
● 防止数据冲突：假设客户端A发给服务端B的一个包在网络里面停留太久；最后本次连接已经结束了，后面又重新建立了一次连接；恰巧这次连接的四元组和上次相同（其实就是源端口刚好相同）。这时序号又是从0开始，而卡了很久的包在这时送到了服务端；因为连接时的序号都是从0开始，这个包的序号如果刚好落在序号段接收的范围内，就会被接收；后面客户端A发送的真正这个序号的包，根据TCP协议，认为是重复，会被丢弃；
● 防止TCP序列号预测攻击：如果TCP序列号可预测，那么攻击者可以利用这一点伪造其他IP地址来发送连接请求，连接建立后，攻击者可以继续假冒，就能随意发送数据给服务器了。
TCP 序列号回绕与解决
初始序列号（ISN）并不是从0开始的，而是采用一定的随机算法产生的，因此ISN可能很大，同一个tcp流的序列号可能会回绕到0。tcp对于丢包和乱序等问题的判断都是依赖于序列号大小比较的，此时就出现了所谓的序列号回绕问题。
内核解决办法：回绕问题的解决很简单，只需要将序列号设置成无符号类型即可，回绕现象并不影响TCP乱序的算法，取后续报文的seq与握手报文seq的差值，永远都是正值且不会有错。

关闭连接为什么是四次挥手？
● 因为TCP是全双工的传输协议，关闭连接操作需要保证双方都关闭了连接。如果只有一端关闭了连接，那么另一端仍然是可以发送数据的。
● 虽然TCP在建立连接的时候，服务器可以将 SYN(同步) 和 ACK (应答) 放在同一个包中发送，但是TCP在关闭连接时，可能需要将 FIN(结束) 和 ACK(应答) 分开发送，这是因为如果服务端收到 FIN(结束) 包之后，仍有数据未发送完，这个时候就需要先给对方回应 ACK(应答) 包，等待剩余的数据发送完毕之后，在像对方发送 FIN(结束) 包来关闭这个方向的TCP连接，因此TCP关闭连接要比建立连接多一次握手。
简答：服务端通常需要等待完成数据的发送和处理，所以服务端的 应答 和 关闭 两个数据包一般都会分开发送，从而比三次握手多了一次。
为什么需要 TIME_WAIT 状态？等待的时间是 2 * MSL (报文最大生存时间)？
● 为了可靠地断开TCP的双向连接，确保有足够的时间让对方收到 ACK (应答) 包，保证双方的连接都可以正常的关闭。
● 因为网络中可能存在来自发送方的数据包，当这些数据包被接收方处理后又会向对方发送响应，所以一来一回需要等待 2 倍的时间。
● 防止旧连接的数据包：等待状态需要持续2倍的MSL，这足以让两个方向上的数据包都被丢弃，使得原来连接的数据包在网络中都消失，这样才能保证再出现的数据包一定都是新的连接所产生的。
TIME_WAIT过多的危害
在Linux系统中，MSL = 60 s， 2 * MSL = 120 s，所以一条待关闭的TCP连接会在 TIME_WAIT 状态等待 120秒（2分钟）。
连接处于TIME_WAIT状态时仍会占用系统资源（fd、端口、内存），当系统的并发连接数很大时，过多的TIME_WAIT状态的连接会对系统的并发量造成影响。
● 对服务器的影响：由于服务器一般只需要监听一个固定的端口，所以服务器所能支持的最大并发出数的上限取决于系统套接字描述符fd的大小，以及服务器的内存大小。
● 对客户端的影响：客户端的并发数主要受限于端口数量。
优化TIME_WAIT的方法：
● 内核参数 tcp_tw_reuse，在调用connect()函数时，内核会随机找一个处于TIME_WAIT状态 超过1秒 的连接给新连接复用，这种方式可以缩短 TIME_WAIT 的等待时间。
● 修改内核参数 tcp_max_tw_buckets：当系统中处于 TIME_WAIT 状态的连接数量超过阈值，系统会将后面的TIME_WAIT连接重置。
● 设置套接字选项 SO_LINGER：SO_LINGER选项用于设置 调用close() 关闭TCP连接时的行为，注意 SO_LINGER选项会使用RST复位报文段取代 FIN-ACK四次挥手的过程，设置了SO_LINGER选项的一方在调用close() 时会直接发送一个RST，接收端收到后复位连接，不会回复任何响应。这样做的弊端是导致TCP缓冲区中的数据被丢弃。
● 设置套接字选项 SO_REUSEADDR：SO_REUSEADDR 选项用于通知内核：如果端口忙，并且端口对应的TCP连接状态为TIME_WAIT，则可以重用端口；如果端口忙，并且端口对应的TCP连接处于其他状态（非TIME_WAIT），则返回 “Address already in use” 的错误信息。SO_REUSEADDR的风险是可能会导致新连接上收到旧连接的数据（复用了旧连接的端口，导致新旧连接的四元组完全一致，内核协议栈无法区分这两个连接）。





Socket 的通信流程？

（1）建立连接阶段
○ 服务器：
■ 调用 socket()，创建套接字
■ 调用 bind()，将套接字与IP地址和端口绑定
■ 调用 listen()，监听特定端口
■ 调用 accept()，等待客户端连接
○ 客户端：
■ 调用 socket()，创建套接字
■ 调用 connect()，向服务器发送建立连接请求
（2）数据交互阶段
○ 调用 send () 发送数据包
○ 调用 receive() 接受数据包
（3）关闭连接阶段
○ 当read()返回0的时候，说明客户端发来了FIN数据包，即关闭连接，调用close()关闭连接套接字和监听套接字

SYN泛洪攻击了解吗？TCP有哪些漏洞？
SYN攻击利用的是TCP的三次握手机制，攻击者利用伪造的IP地址向服务器发送TCP连接请求，服务器接受到请求之后会处于 SYN_RCVD（同步接受）状态，并且向对方发送应答报文，但是对方是无法做出响应的，如果有很多这种半连接状态的TCP连接占用服务器资源，服务器将无法为正常用户提供服务。
为什么半连接会占用服务器资源：
在客户端发起第一次连接时，服务端会将其加入到syn队列中，并且响应客户端syn+ack报文，等到客户端发送ack应答报文时，服务端将该连接从半连接队列中取出，并新建一个新的连接，加入到accept队列当中。等待进程调用accept请求时，将该连接取出来。不管是半连接队列还是全连接队列，都有最大长度限制，超过限制时，内核会直接丢弃，或返回 RST 包。
防范措施：
● 降低 SYN_RCVD 状态的超时时间，使得主机尽快释放半连接的占用；
● 采用 SYN cookie 设置，如果短时间内连续收到某个IP的重复SYN请求，则认为受到了该IP的攻击，丢弃来自该IP的后续请求报文；
● 使用防火墙等网络安全设备

TCP 通过哪些机制实现可靠性？
● TCP的三次握手与四次挥手
● 重传机制
● 滑动窗口
● 流量控制
● 拥塞控制

TCP 重传机制了解吗？有哪些？
TCP 重传机制是为了保证数据包传输的可靠性，保证每个数据包都能够到达目的地，TCP常用的重传机制有：
○ 超时重传
■ 定义：超时重传是一种主动重传的方式，当发送端没有在指定的时间内接收到对方的 ACK(应答) 报文后，就会重发数据。
■ TCP 会在以下两种情况发生超时重传：数据包丢失、确认应答包丢失
■ 缺点：超时时间不好设置。因为当超时时间较大时，重发就慢，没有效率；当超时时间较小时，会导致可能并没有丢包就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，恶性循环。超时重传的时间应该略大于报文往返的时间。但是报文的往返时间是不确定的，它是动态变化的，因此需要通过连续采样来计算一个比较合适的值作为当前的超时时间。
○ 快速重传
■ 定义：如果说超时重传是以超时时间为驱动的，那么快速重传就是以数据作为驱动的。当接收端收到数据包的序列号不太正常时，接收端使用期望的序列号作为应答报文，用这种方式来提醒发送端重传数据。一般来说，当发送端收到连续3条的相同序列号的应答报文，就意识到这个包丢了，从而立即重传该数据包。
■ 缺点：快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是重传的时候，是重传之前的一个，还是重传所有的数据包。
○ SACK
○ D-SACK

TCP的滑动窗口
TCP 引入了滑动窗口是为了解决一应一答的数据的传输方式，数据包的往返时间越长，通信的效率就越低。有了窗口，就可以无需等待确认应答而可以继续发送数据。窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。
窗口大小由哪一方决定？
TCP 头里有一个字段叫 Window，也就是窗口大小。这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。所以，通常窗口的大小是由接收方的窗口大小来决定的。
TCP的流量控制
发送方不能无脑的发数据给接收方，要考虑接收方处理能力。如果一直无脑的发数据给对方，但对方处理不过来，那么就会导致触发重发机制，从而导致网络流量的无端的浪费。为了解决这种现象发生，TCP 提供一种机制可以让「发送方」根据「接收方」的实际接收能力控制发送的数据量，这就是所谓的流量控制。
TCP的拥塞控制
为什么需要拥塞控制？
拥塞控制的目的就是避免发送方的数据填满整个网络，因为网络是一个共享的环境，发送大量数据包可能会导致网络出现拥堵，进而导致丢包，丢包又会导致TCP重传，是网络负担更重，恶性循环。
如何知道当前网络是否出现了拥塞呢？
其实只要发送方没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络 出现了用拥塞。
拥塞控制主要是四个算法：
● 慢启动
● 拥塞避免
● 拥塞发生
● 快速恢复
● 慢启动：TCP 在刚建立连接完成后，首先是有个慢启动的过程，这个慢启动的意思就是一点一点的提高发送数据包的数量，但是这个过程不会一直提高，它有一个启动门限或者说阈值，如果当前的传输速率小于这个阈值，就会使用慢启动算法，否则就会使用拥塞避免算法。
● 拥塞避免：拥塞避免算法会将原本慢启动算法的指数增长变成了线性增长，还是处于增长阶段，但是增长速度缓慢了一些。如果一直持续增长，那么网络就会慢慢进入了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进行重传。当触发了重传机制，就会进入拥塞发生算法。
● 拥塞发生：当网络出现拥塞，也就是会发生数据包重传，在TCP中，有两种重传机制，一种是超时重传，另外一种是快速重传，这两种使用的拥塞发送算法是不同的。当发生了「超时重传」，则会使用拥塞发生算法，这会中情况会重新开始慢启动过程，数据流也会突然减少。如果发生「快速重传」，那么会使用快速恢复算法。
● 快速恢复：当拥塞发生导致快速重传，则会使用快速恢复，相比于拥塞发送算法，快速重传算法不会重新开启慢启动过程，而是将发送速率降低到某个值，这个值一般大于启动门限，因此还是会进行线性的提高发送速率。
神奇的40ms
Nagel算法和延迟ACK机制共同导致的数据包延迟发送。
● Nagle算法主要是避免发送小的数据包，要求TCP连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其他的小分组。相反，TCP收集这些少量的小分组，并在确认到来时以一个分组的方式发出去。linux提供了TCP_NODELAY的选项来禁用Nagle算法。
● 接收方在收到数据后，并不会立即回复ACK,而是延迟一定时间。一般ACK延迟发送的时间为200ms，但这个200ms并非收到数据后需要延迟的时间。系统有一个固定的定时器每隔200ms会来检查是否需要发送ACK包。这样做有两个目的。
○ 这样做的目的是ACK是可以合并的，也就是指如果连续收到两个TCP包，并不一定需要ACK两次，只要回复最终的ACK就可以了，可以降低网络流量。
○ 如果接收方有数据要发送，那么就会在发送数据的TCP数据包里，带上ACK信息。这样做，可以避免大量的ACK以一个单独的TCP包发送，减少了网络流量。


TCP 和 UDP 有哪些区别？
从以下几个方面来说明：
○ 连接
■ TCP 是面向连接的传输层协议，传输数据前先要建立连接
■ UDP 是不需要连接，即刻传输数据
○ 服务对象
■ TCP 是一对一的两点服务
■ UDP 支持一对一、一对多、多对多的交互通信
○ 可靠性
■ TCP 是可靠交付数据的
■ UDP 是尽最大努力交付，不保证可靠交付数据
■ TCP 有拥塞控制和流量控制，能够保证数据传输的效率；UDP 没有这些丰富的控制机制来保证数据的传输可靠性。
○ 首部开销
■ TCP 首部长度较长，会有一定的开销
■ UDP 首部只有 8 个字节，并且是固定不变的，开销较小
○ 传输方式
■ TCP 是数据流的传输方式，包与包之间没有边界，但是能保证顺序和可靠性
■ UDP 是一个包一个包的发送，是有边界的，但可能会丢包和乱序
TCP 协议有什么缺陷？
● TCP 建立连接的延迟：基于 TCP 实现的应用协议，都是需要先建立三次握手才能进行数据传输，比如 HTTP 1.0/1.1、HTTP/2、HTTPS。现在大多数网站都是使用 HTTPS 的，这意味着在 TCP 三次握手之后，还需要经过 TLS 四次握手后，才能进行 HTTP 数据的传输，这在一定程序上增加了数据传输的延迟。
● 存在队头阻塞问题：TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且有序的，如果序列号较低的 TCP 段在网络传输中丢失了，即使序列号较高的 TCP 段已经被接收了，应用层也无法从内核中读取到这部分数据。
粘包和拆包
TCP 是面向字节流的协议，所谓流，就是没有界限的一串数据，它会根据 TCP 缓冲区的实际情况进行包的划分，实际情况可能有：
● 当 TCP 发送缓冲区剩余空间不足时，一个完整的包可能会被拆分为多个包进行发送，即可能发生拆包情况。
● 当 TCP 发送缓冲区剩余空间足够时，多个小的包也有可能被封装成一个大的包进行发送，即可能发生粘包情况。
发生粘包和拆包的原因除了上面两种情况，还有以下原因：
● TCP协议具备一些流量控制、窗口机制来保证数据传输的效率，比如TCP为了避免每次发送小数据包，使用了Nagle算法来提高数据的传输效率，该算法的思路就是延时发送数据包，直到数据大小合适之后，再一起发送出去。也就是小的数据会合并成一个大的数据，然后进行封包传输，这种情况就发生了粘包现象。
● 数据包过大时，TCP 为了避免被分片，会主动把数据分割成小段再交给网络层，这种情况也发生了拆包现象。
粘包的解决方案：
● 使用定长的数据包进行传输，也就是使用固定大小的报文进行传输。
● 使用分隔符将数据包分隔开来，比如使用回车或者空格等特殊字符。
● 使用带有长度信息的协议，将消息分为消息头和消息体，这样就能够获取到完整的数据包了。
UDP有粘包问题吗？
TCP 之所以存在拆包和粘包问题，本质就是 TCP 是面向字节流的协议，字节流协议是无边界的协议；而像 UDP 是面向报文的，客户端连续发送多个包并不会发生粘包现象，每一个包都是独立的，发送的时候也是以一个一个包为单位，接收的时候也是。
UDP 报文格式

UDP传输的段（segment）有8个字节的报头和有效载荷字段构成。UDP报头由4个域组成，其中每个域各占用2个字节，具体包括源端口号、目标端口号、数据报长度、校验值。
○ 源端口：源端口号
○ 目的端口：目的端口号
○ 长度：UDP用户数据报的长度，包括报头和数据部分在内的总字节数，其最小值是8（仅有首部）。
○ 检验和：检测UDP用户数据报在传输中是否有错。有错就丢弃。
UDP 数据包的最大长度是多少？
● 理论情况：UDP 数据包的最大长度约为 216 ( 约等于 64K )
● 实际情况：但是通常不会使用UDP传输大的数据包，因为UDP是一个不可靠的传输协议，传输大数据包的时候，会在IP层进行分片，传输的过程中有可能会发生丢包的现象，而且其顺序也无法保证。
一般来说，使用UDP传输数据的最合适的长度应该小于1480字节，因为以太网数据帧的最大传输单元(MTU)通常为1500字节，减去IP首部的长度(20字节) 刚好等于1480字节，又因为UDP数据包的首部包含8字节，所以UDP数据报的数据部分最大长度应为 (1480-8 = 1472 ) 字节，这个1472字节才是可以使用的字节数。
UDP 的适用场景
由于 UDP 面向无连接，它可以随时发送数据，再加上UDP本身的处理既简单又高效，因此经常用于：
○ 包总量较少的通信，如 DNS 、 SNMP 等
○ 视频、音频等多媒体通信
○ 广播通信
为什么 UDP 头部没有「首部长度」字段，而 TCP 头部有「首部长度」字段呢？
TCP 有可变长的「选项」字段，而 UDP 头部长度则是不会变化的，无需多一个字段去记录 UDP 的首部长度。
I/O
同步和异步 & 阻塞和非阻塞
阻塞和非阻塞应该描述的是一种状态，同步与非同步描述的是行为方式。
● 同步和异步：同步就是在发出一个调用时，在没有得到结果之前， 该调用就不返回；异步则是相反，调用在发出之后，这个调用就直接返回了，所以没有返回结果，被调用者处理完成后通知回调、通知等机制来通知调用者；
● 阻塞和非阻塞：阻塞/非阻塞关注的是程序在等待调用结果时的状态，阻塞调用是指调用结果返回之前，当前线程会被挂起，调用线程只有在得到结果之后才会返回；非阻塞调用指在不能立刻得到结果之前，该调用不会阻塞当前线程。

阻塞I/O

当用户进程调用了 read 之后，系统内核就开始了I/O的第一个阶段：准备数据。对于网络I/O来说，很多时候数据在一开始还没有到达，这个时候内核就要等待足够的数据到来。而在用户进程这边，整个进程会被阻塞，当数据准备好时，它就会将数据从内核拷贝到用户空间并返回结果，用户进程才解除阻塞的状态，重新运行起来。
特点	在I/O执行的两个阶段（等待数据和拷贝数据）都会被阻塞
典型应用	阻塞Socket，Java BIO
优点	1. 进程阻塞挂起时不消耗CPU资源，及时响应每个操作
2. 实现难度低，适合并发量小的网络应用开发
   缺点	1. 不适合并发量大的应用，因为一个请求I/O会阻塞进程
2. 需要为每个请求分配一个线程处理，系统开销大
   阻塞IO缺点带来的思考：
   因为accept()、recv()函数都是阻塞的，如果系统想要支持多个IO请求，就创建更多的线程，如果去解决这个问题呢？如果可以把accept、recv函数变成非阻塞的方式，是不是就可以避免创建多个线程了？这就引入了我们的同步非阻塞IO。
   非阻塞I/O

1. 用户进程发起请求调用read()函数，系统内核收到read()系统调用，网卡开始准备接收数据
2. 内核缓冲区数据没有准备好，请求立即返回，用户进程不断的重试查询内核缓冲区数据有没有准备好
3. 当内核缓冲区数据准备好了之后，用户进程阻塞，内核开始将内核缓冲区数据复制到用户缓冲区
4. 复制完成后，用户进程解除阻塞，读取数据继续执行
   特点	用户进程需要不断地主动询问内核数据是否准备好
   典型应用	Socket 设置为 NON_BLOCK
   优点	1. 非阻塞，用户线程立即返回
   缺点	1. 进程重复调用（轮询），比较消耗CPU资源
2. 适合并发量小且不需要及时响应的网络应用开发
   非阻塞IO缺点带来的思考：
   针对同步非阻塞IO的缺点，设想如果内核提供一个方法，可以一次性把多个客户端socket连接传入，在内核中去遍历，如果没有数据这个方法就一直阻塞，一但有数据这个方法解除阻塞并把所有有数据的socket返回，把这个遍历的过程交给内核去处理，是不是就可以避免空跑，避免多次用户态到内核态的切换呢？
   多路复用I/O

多路复用I/O也可以称为事件驱动I/O。
IO多路复用模型是建立在内核提供的多路分离函数select基础之上的，使用select函数可以避免同步非阻塞IO模型中轮询等待的问题，即一次性将N个客户端socket连接传入内核然后阻塞，交由内核去轮询，当某一个或多个socket连接有事件发生时，解除阻塞并返回事件列表，用户进程在循环遍历处理有事件的socket连接。这样就避免了多次调用recv()系统调用，避免了用户态到内核态的切换。
多个进程的I/O可以注册到一个复用器（Selector）上，当用户进程调用该Selector，Selector会监听注册进来的所有I/O，如果Selector监听的所有I/O在内核缓冲区都没有可读数据，select调用进程会被阻塞，而当任一I/O在内核缓冲区中有可读数据时，select调用就会返回，而后select调用进程可以自己或通知另外的进程（注册进程）再次发起读取I/O，读取内核中准备好的数据，多个进程注册I/O后，只有一个select调用进程被阻塞。Select的好处就在于可以同时处理多个网络I/O，其基本原理就是 select/epoll 这个功能会不断轮询所有负责的Socket，因此多路复用I/O相对于Selector来说是非阻塞式的。
特点	对于每个Socket，一般都设置为非阻塞，但是整个用户的进程其实是一直被阻塞的，只不过进程是被Select阻塞的，而不是被Socket I/O阻塞的
典型应用	Java NIO, Nginx ( epoll, poll, select)
优点	1. 专一进程解决多个进程I/O阻塞问题，性能好，Reactor模式
2. 适合高并发服务应用开发，一个进程/线程响应多个请求
   缺点	1. 实现和开发难度大
   IO多路复用的三种实现：
   select：
   select函数仅仅知道有I/O事件发生了，但并不知道具体是哪个socket连接有I/O事件，还需要轮询去查找，时间复杂度为O(n)，处理的请求数越多，所消耗的时间越长。
   poll：
   poll本质上和select没有区别，它将用户传入的数组拷贝到内核空间，然后查询每个fd对应的设备状态， 但是它没有最大连接数的限制，原因是它是基于链表来存储的。
   epoll：
   epoll可以理解为event pool，不同与select、poll的轮询机制，epoll采用的是事件驱动机制，每个fd上有注册有回调函数，当网卡接收到数据时会回调该函数，同时将该fd的引用放入rdlist就绪列表中。当调用epoll_wait检查是否有事件发生时，只需要检查eventpoll对象中的rdlist双链表中是否有epitem元素即可。如果rdlist不为空，则把发生的事件复制到用户态，同时将事件数量返回给用户。
   select、poll采用轮询的方式来检查文件描述符是否处于就绪态，而epoll采用回调机制。造成的结果就是，随着fd的增加，select和poll的效率会线性降低，而epoll不会受到太大影响，除非活跃的socket很多

什么是零拷贝？
传统 I/O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I/O 接口从磁盘读取或写入。


期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。
发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：
● 第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。
● 第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。
● 第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。
● 第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。
要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。

零拷贝技术实现的方式通常有 2 种：
● mmap + write
● sendfile
mmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。

mmap + write 具体过程如下：
● 应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；
● 应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；
● 最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。
我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。

sendfile() 系统调用的过程发生了点变化，具体过程如下：
● 第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；
● 第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；
零拷贝（Zero-copy）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。