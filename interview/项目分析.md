开场白：
面试官你好，我叫dp,上一段工作在虾皮做goland后端开发；所在的部门是本地生活，主要负责商品的创建，以及用户搜索流程；平时主要负责新需求的设计开发工作，负责组内主要项目的版本更新维护，及时处理线上问题并快速修复。
项目一：全局搜索优化？

说说你们全局搜索的项目，项目的难点？
全局搜索优化背景：
全局搜索优化项目，背景主要是为了提高用户的搜索效率，使用户的搜索结果更加准确，而我们的业务在接入算法推荐之前，商品和门店的搜索这些场景几乎完全依赖ES的搜索，但是ES的搜索结果也不能完全瞒住我们的预期，所以我们对用户输入的搜索词进行一个预处理，这个预处理过程是包括搜索词纠错、同义词扩展以及实体词识别这些流程，相当于对用户的输入进行优化，
在架构层面对组件的职责进行重新划分，我们的接口api服务只负责基本的参数校验和首页缓存，搜搜服务主要负责过滤，搜索和排序的逻辑；新增加的聚合服务负责搜索之前的前置处理以及对搜索结果的补全，原来的架构逻辑比较冗余耦合，所有列表展示接口和搜索接口放在一起，通过前端增加关键词进行区分；之后对其进行拆分，分为搜索接口和列表接口，使代码更容易阅读。

先介绍一下搜索词预处理，刚刚提到了搜索词纠错、同义词扩展以及实体词识别这三个流程，搜索词纠错是由我们业务来做的，而后两者是通过接入算法推荐来获得的，之所以纠错这块的放到我们业务这块来做，是因为有一部分纠错词是由运营他们来手动配置的，这块业务放在了Admin上管理，手动配置的纠错词相对比较简单，就是原词和纠错词之间的映射，一个原词可能会对应多个纠错词，这样形成一个手动纠错的词典；当然还有一个自动纠错词典，这个词典只包含关键词，一般来讲，我们会把品牌名称导入这个词典来作为我们的品牌名纠错词典。对用户输入的搜索词进行纠错，会优先查询手动纠错词典中是否存在，否则就在自动纠错的词典中寻找，在自动纠错的词典中，我们会计算搜索词与词典中的词之间的最小编辑距离（这里只包括插入、删除和替换这三种编辑操作），并根据这个值来进行优先级排序，取前3作为我们的纠错词。通常来讲，还会提前设置一个最小编辑距离的阈值（1/2），主要是为了提升性能，而且太大了也没意义。这两个词典的构建是在服务启动之后加载到内存中，每隔一段时间会进行一次刷新。对于用户的搜索词纠错结果，我们还会缓存一段时间，这个也是为了在大促期间降低服务的压力。以上基本是就是纠错的一些细节。
然后再说一下搜索的过程，我们拿到用户输入的搜索词之后，会经过纠错并且查询算法推荐的接口拿到对应的同义词和实体词（这里使用到这么多词的原因主要是为了扩充搜索的召回数量）。然后再使用原词、纠错词、同义词等这些关键词去ES进行搜索召回，我们会根据门店、商品、品牌、类型、位置等这些信息进行多路召回，每路召回包括了精确匹配、前缀匹配、短语匹配和模糊匹配这四种搜索语句，当然这几种搜索语句在ES中都有对应的 functino score 进行权重评分，那么通过这些评分就能拿到一个粗排结果。到这一步，这个排序结果在搜索词相关性方面其实已经算比较好的结果了，但是还缺少其他维度的排序，因此之后还要进行一次精排。我们会根据相关性得分进行最大最小归一化，以及门店距离、商品销量等因素再次进行权重排序。到这一步基本上就完成整个搜索的过程。
在这个需求上线前，还需要进行一些权重调整，由算法推荐他们提供样本进行调参配置。除此之外还需要，进行AB-Test实验分组，用于对比和效果分析。
整个需求的难点：
■ 测试和压测：我们验证最终的排序结果是否符合预期，而我们的测试环境的数据量又比较小，所以不一定能把所有的情况都覆盖掉，因此还有补充一些单测去验证一些方法的正确性。同时还需要对接口进行压测，因为我们的ES搜索语句相比之前增加了很多路召回，对ES是一种负担，所以除了考虑功能和性能的平衡之外，还需要补充ES降级一套方案，避免在大促期间ES集群告警。
■ nested 结构处理brand 和city 的关系

距离召回方式：
"post_filter": {
"geo_distance": {
"distance": "5km",
"location": {
"lat": 39.920086,
"lon": 116.454182
}
}
}

"sort": [
{
"_geo_distance": {
"location": {
"lat": 39.920086,
"lon": 116.454182
},
"order": "asc",
"unit": "km"
}
}
]

方案
搜索纠错的词典设计、运营的纠错管理；
推荐团队的实体词识别和同义词扩展模块的接入；
ES多路召回和排序模型的实现；
搜索接口的调参与AB-Test实验分组
搜索词纠错
当前LS搜索的详细流程为：
● 用户输入搜索词之后会经过纠错模块，纠错模块主要基于词典实现
● 原词/纠错词会进行三路并行召回，分为：基于outlet索引的outlet_name字段召回、基于outlet索引的brand_name字段召回、基于item索引的item_name字段召回
○ 每路召回的检索策略包括：
■ 精准匹配(term)
■ 前缀匹配(prefix)
■ 短语匹配(match_phrase)
■ 词条匹配(match)
○ 每路召回规则排序策略为：
■ 相关性tab：虚拟店优先实体店，其次按照相关性，然后按照距离，然后按照销量，最后是商店id
■ 距离tab：实体店优先虚拟店，其次按照距离，然后按照销量，最后是商店id
■ 销售tab：虚拟店优先实体店，其次按照销量，然后按照距离，最后是商店id
■ 热度tab：虚拟店优先实体店，其次按照销量/距离，最后是商店id
● 多路并行召回过程中存在去重功能，目前优先级是outlet_name召回>brand_name召回>item召回，因此在基于outlet索引的brand_name召回的过程中，会过滤掉outlet索引中outlet_name命中的情况；同时可以发现每路召回的结果都是在当前路召回中已排序的多路结果进行merge排序得到最终的topN结果，merge规则排序的策略为：
○ 相关性tab：outlet_name召回结果优先展示，其次展示brand_name召回结果(直接合并到outlet_name结果的后面)，最后展示outlet_name召回结果(直接合并到brand_name结果的后)
○ 距离tab/销量tab：对多路结果进行归并排序




项目亮点：
1. 增加一层聚合服务，使每部分的服务的职能更加准确，
2. 对关键字进行纠错处理，采用多路召回模式，对商品，门店商户进行召回；
   最终效果：
1. 各部分服务职责分明，减轻api-server 服务的压力， 代码看上去更加清晰易懂
2. 实现用户对brand 的召回，提高用户搜索的准确度以及购买率

项目一：redis bigkey监控

bigkey 可能导致什么问题？
在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素，但实际上中如果下面两种情况，我就会认为它是bigkey。
● 字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。
● 非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多，超过5000个就认为是bigkey。
● 内存分布不均
● 超时阻塞
● 网络拥塞


bigkey 怎么解决的？
redis-cli提供了--bigkeys来查找bigkey

项目亮点：
1. 采用业务侧统一封装实时对key进行上报，
2. 采用普罗米修斯的直方图 的方式进行监控并上报到群里
   项目难点：
1. 快速定位bigkey 并进行拆分
   成果：
1. 成功检测bigkey 并进行上报，效果显著



es中存放的是什么数据？ 数据量有多大？你们分片有多少个？
es 中一共3个索引，分别是item，outlet,mall, 数据量较大70万个；
分片的话，一共9个节点，每个分片一个副本；读取较多，副本不宜过多；
es是怎么进行搜索的？
query and feath

https://blog.csdn.net/qq_15758463/article/details/124396565

https://blog.csdn.net/wlei0618/article/details/125060635
https://blog.csdn.net/weixin_42586723/article/details/120441348
es如何保证数据的读写一致性？
● 可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
● 另外对于写操作，一致性级别支持 quorum/one/all，默认为 quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
● 对于读操作，可以设置 replication 为 sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置 replication 为 async 时，也可以通过设置搜索请求参数_preference 为 primary 来查询主分片，确保文档是最新版本。


项目三：kafka 监控多活？


说说你们的项目？ 遇到什么难点了么？

项目难点：
1. kafka 底层sdk 兼容性问题
2. kafak 多活容灾故障切换方式 2种
   项目亮点：
1. 采用segmentio-kafka 进行统一，性能更好
2. 采用MM2进行数据同步，保证数据的一致性
   ● 同城双活是在同城或相近区域内建立两个机房。同城双机房距离比较近，通信线路质量较好，比较容易实现数据的同步复制 ，保证高度的数据完整性和数据零丢失。
   ● 难点： 版本统一遇到兼容性问题（引出segmentio）；数据发送分区问题(引出key 进行发送)；多活容灾故障切换问题（引出怎么故障切换的）；

1. 所有AZ的Producer向Main-AZ的Kafka集群生产消息；
2. Main-AZ的Kafka消息通过MM2复制到DR-AZ；
3. 仅Main-AZ的Consumer启动并消费消息
   MM2是什么东西？ 为什么选用这个？
   ● 其实现原理，其实就是通过从Source Cluster消费消息然后将消息生产到Target Cluster，即普通的消息生产和消费。用户只要通过简单的consumer配置和producer配置，然后启动Mirror，就可以实现准实时的数据同步
   ● 使其能够动态修改配置，并且能够将Topic在群集之间保持同步，同时尽可能地降低触发Rebalance的情况以提高性能
   ● MirrorMaker2中使用的Kafka Connect框架原生采用了Kafka的High Level Consumer从Kafka读取数据。High Level Consumer会自动地使Consumer Group中消费的分区在整个组中自动平衡。每次Topic的元数据发生更改时，例如改分区计数，或更改Connect Worker的数量等等，会触发Connect  rebalance。频繁的重新平衡会导致阻塞，并且严重的影响Target集群的吞吐。
   ● 在MM V2中，我们使用了Low Level Consumer 去Consume给定的分区列表，因此可以避免由于Topic的分区数更改而触发的Rebalance动作。因此，对Topic和分区数的任何更改都不会导致完全的重新平衡。但是，需要注意的是，由Connect集群本身（例如添加更多Worker Node等）的更改触发的重新平衡是无法避免的。在大多数情况下，这些变化比Topic的变化次数要少的多。





为什么选用segmentio-kafka?
● confluent-kafka-go包[是kafka背后的技术公司confluent.inc维护的Go客户端，也可以算是Kafka官方Go客户端了。不过这个包唯一的“问题”在于它是基于kafka c/c++库librdkafka[18]构建而成，这意味着一旦你的Go程序依赖confluent-kafka-go，你就很难实现Go应用的静态编译，也无法实现跨平台编译。由于所有业务系统都依赖log包，一旦依赖confluent-kafka-go只能动态链接，我们的构建工具链全需要更改，代价略大。
● 和sarama一样，segmentio/kafka-go也是一个纯go实现的kafka client，并且在很多公司的生产环境经历过考验，segmentio/kafka-go提供低级conn api和高级api(reader和writer)，以writer为例，相对低级api，它是并发safe的，还提供连接保持和重试，无需开发者自己实现，另外writer还支持sync和async写、带context.Context的超时写等。


kafka集群容灾切换怎么切换的？
1. 非故障流量切换SOP
   ● 业务日常运行过程中，由于某种需要(比如演练、流量实验等)，需要调整部分流量的分发规则(将userA的分片规则从Main-AZ修改至DR-AZ)，这种场景称为非故障流量切换
   ● 非故障流量切换场景下，对Kafka模块来说，无需做任何操作

1. DR-AZ故障时流量切换SOP
   ● 业务运行过程中，DR-AZ发生故障，需要将流量全部切换至Main-AZ，GRS服务修改routing-force=Main。对Kafka模块来说，无需做任何操作
2. Main-AZ故障时流量切换SOP
   ● Main-AZ发生故障时，GRS服务修改routing-force=DR；
   ● 服务监听到routing-force=DR，自动启动DR-AZ的Consumer，并关闭Main-AZ的Consumer；
   ● DEV同学手动修改Kafka Apollo Config，设置MainTopicSeekToEnd=1，代表后续要将Main-AZ的Consumer Offset设置为最新【人工介入】；
   ● Main-AZ恢复后，GRS服务修改routing-force，Main-AZ接收流量，Main-AZ启动Producer和Consumer(Consumer要将offset设置为最新)，DR-AZ关闭Consumer。
1.  Main-AZ的Kafka集群故障切换SOP
    Main-AZ业务服务正常运行，仅Kafka集群出现故障，执行Kafka集群故障处理流程：
1. 在Kafka Apollo Config修改Main-AZ的Kafka Brokers配置；
2. 服务监听Brokers地址发生变化，重建链接池，链接至DR-AZ的Kafka集群，业务正常运行；
3. Main-AZ的Kafka集群恢复后，修改Main-AZ的Kafka Brokers配置，重新链接Main-AZ的Kafka集群。
   2、Main-AZ故障恢复时，DR-AZ的剩余Kafka消息如何处理
   正常情况下，Main-AZ承载95%的流量，DR-AZ承载5%的流量。Main-AZ出现故障时，由DR-AZ承载全部流量，此时会向DR-AZ生产消息。当Main-AZ恢复后，流量切换至Main-AZ，DR-AZ未消费的数据如何处理？
   解决方案1【推荐】:  在上述方案设计中，Main-AZ恢复后，Main-AZ接收流量，会将DR-AZ的Consumer关闭，并且DR-AZ的Kafka数据不会向Main-AZ同步，因此会有部分未消费的数据丢失。考虑到故障恢复的时间点可控，可以选择流量低峰期进行流量切换，因此DR-AZ丢失的数据量应该可接受。
   解决方案2:  如果需要做到DR-AZ不丢失数据，可以在Apollo增加开关“DRKeepConsume”，代表是否需要DR-AZ的Consumer继续消费。
   正常情况下DRKeepConsume = false，在Main-AZ恢复时，设置DRKeepConsume = true，标记Main-AZ的Consumer暂不消费，DR-AZ的Consumer继续消费(Main-AZ已经开始接收流量，但不消费，也不会影响DR-AZ的消费处理逻辑)。等DR-AZ的Kafka消息全部消费完，再设置DRKeepConsume = false，关闭DR-AZ的Consumer，Main-AZ的Consumer开始消费。此方案需要引入新的控制开关，且需要人工操作和观察消费进度，暂不推荐。
   数据一致性有保证么？
   kafka是通过HW（High Water Mark） 机制来保证数据的一致性。
   1）follower故障
   follower发生故障后会被临时踢出ISR，待该follower恢复后，follower会读取本地磁盘记录的上次的HW，并将log文件高于HW的部分截取掉，从HW开始向leader进行同步。等该follower的LEO大于等于该Partition的HW，即follower追上leader之后，就可以重新加入ISR了。

（2）leader故障
leader发生故障之后，会从ISR中选出一个新的leader，之后，为保证多个副本之间的数据一致性，其余的follower会先将各自的log文件高于HW的部分截掉，然后从新的leader同步数据。


kafka 中消息有序的么？
kafka每个partition中的消息在写入时都是有序的，消费时，每个partition只能被每一个group中的一个消费者消费，保证了消费时也是有序的。
整个topic不保证有序。如果为了保证topic整个有序，那么将partition调整为1。

什么是kafka 消费者组？ 什么是重平衡？ 什么时候会触发？ 怎么避免？
● 消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程。Rebalance 是 Kafka 消费者端实现高可用的重要手段。
● 消费者组（Consumer Group）是由一个或多个消费者实例（Consumer Instance）组成的群组，具有可扩展性和可容错性的一种机制。消费者组内的消费者共享一个消费者组ID，这个ID 也叫做 Group ID，组内的消费者共同对一个主题进行订阅和消费，同一个组中的消费者只能消费一个分区的消息，多余的消费者会闲置，派不上用场。




kafka 为什么如此之快？

● kafka 实现了零拷贝原理来快速移动数据，避免了内核之间的切换。Kafka 可以将数据记录分批发送，从生产者到文件系统（Kafka 主题日志）到消费者，可以端到端的查看这些批次的数据。
● 批处理能够进行更有效的数据压缩并减少 I/O 延迟，Kafka 采取顺序写入磁盘的方式，避免了随机磁盘寻址的浪费
● 简而言之：
● 顺序读写
● 零拷贝
● 消息压缩
● 分批发送

kafka 是否会丢失消息以及重复消费？

要确定Kafka的消息是否丢失或重复，从两个方面分析入手：消息发送和消息消费。
1）消息发送 Kafka消息发送有两种方式：同步（sync）和异步（async），默认是同步方式，可通过producer.type属性进行配置。Kafka通过配置request.required.acks属性来确认消息的生产：
● 0---表示不进行消息接收是否成功的确认；
● 1---表示当Leader接收成功时确认；
● -1---表示Leader和Follower都接收成功时确认；
综上所述，有6种消息生产的情况，下面分情况来分析消息丢失的场景：
（1）acks=0，不和Kafka集群进行消息接收确认，则当网络异常、缓冲区满了等情况时，消息可能丢失；
（2）acks=1、同步模式下，只有Leader确认接收成功后但挂掉了，副本没有同步，数据可能丢失；
2）消息消费
Kafka消息消费有两个consumer接口，Low-level API和High-level API：
● Low-level API：消费者自己维护offset等值，可以实现对Kafka的完全控制；
● High-level API：封装了对parition和offset的管理，使用简单；
如果使用高级接口High-level API，可能存在一个问题就是当消息消费者从集群中把消息取出来、并提交了新的消息offset值后，还没来得及消费就挂掉了，那么下次再消费时之前没消费成功的消息就“诡异”的消失了；
3）解决办法
● 针对消息丢失：同步模式下，确认机制设置为-1，即让消息写入Leader和Follower之后再确认消息发送成功；异步模式下，为防止缓冲区满，可以在配置文件设置不限制阻塞超时时间，当缓冲区满时让生产者一直处于阻塞状态；
● 针对消息重复：将消息的唯一标识保存到外部介质中，每次消费时判断是否处理过即可。












